# Multi-Agent Translation Semantic Drift Experiment

> **Latest Experiment Results**: This project contains a complete automated experiment testing semantic drift across 21 sentences with 7 typo rates (20%-50%). All results are verified and documented in `results/quantitative_analysis.md`.
>
> **Quick Start**: See [Understanding Results](#understanding-results) for analysis of the latest experiment.
> **Visualization**: View `results/semantic_drift_analysis.png` for complete graphs (auto-generated by `batch_calculate_distances.py`).

---

## Table of Contents
- [Overview](#overview)
- [What is This Project?](#what-is-this-project)
- [Multi-Agent Architecture](#multi-agent-architecture)
- [How It Works](#how-it-works)
- [Installation](#installation)
- [Experiment Types](#experiment-types)
  - [User Input Experiments](#user-input-experiments)
  - [Automated Experiments](#automated-experiments)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Agent and Skill Descriptions](#agent-and-skill-descriptions)
- [Experiment Configuration](#experiment-configuration)
- [Understanding Results](#understanding-results)
- [Example Runs](#example-runs)

---

## Overview

This project demonstrates **multi-agent orchestration** with semantic drift measurement caused by spelling errors across multiple language translations. It showcases how autonomous agents can communicate through files and coordinate complex workflows.

**Key Concept**: When text with spelling errors is translated through multiple languages and back to English (English â†’ French â†’ Italian â†’ English), how much does the semantic meaning change compared to the original?

---

## What is This Project?

Imagine you have a sentence in English, but some words are misspelled. You translate it to French, then to Italian, then back to English. When you compare the final English translation to the original English (using semantic embeddings), how different is the meaning?

This project **automates that entire process** using a clear separation of responsibilities:

**Claude LLM handles:**
- Sentence generation (creating original English sentences >15 words)
- Typo injection (manually introducing spelling errors at 20-50% rates)
- Translation coordination (via autonomous Claude agents)
- Qualitative analysis (observing semantic drift, meaning changes)
- Report generation (comprehensive markdown with tables and insights)

**Python handles (ONLY at the end):**
- Embedding computation (converting text to 384-dim vectors)
- Distance calculation (cosine distance between embeddings)
- Graph generation (matplotlib visualizations)

**Key principle:** Claude does all the language work; Python does all the math.

The result is a measurement of **semantic drift** - how far the meaning has drifted from the original.

---

## Multi-Agent Architecture

### Conceptual Flow

```
User provides sentence with typos
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MAIN ORCHESTRATOR AGENT               â”‚
â”‚   - Saves original sentence             â”‚
â”‚   - Coordinates the workflow            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSLATOR 1 AGENT                    â”‚
â”‚   - Translates: English â†’ French        â”‚
â”‚   - Writes: tmp/first_hop_translation.mdâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSLATOR 2 AGENT                    â”‚
â”‚   - Reads: tmp/first_hop_translation.md â”‚
â”‚   - Translates: French â†’ Italian        â”‚
â”‚   - Writes: tmp/second_hop_translation.mdâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSLATOR 3 AGENT                    â”‚
â”‚   - Reads: tmp/second_hop_translation.mdâ”‚
â”‚   - Translates: Italian â†’ English       â”‚
â”‚   - Writes: tmp/third_hop_translation.mdâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ORCHESTRATOR (calls Python)           â”‚
â”‚   - Reads: original + final translation â”‚
â”‚   - Calls: python calculate_distance.pyâ”‚
â”‚   - Python computes embeddings & distanceâ”‚
â”‚   - Reports semantic distance           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Result displayed to user
```

### Key Design Principles

1. **Agent Autonomy**: Each agent operates independently
2. **File-Based Communication**: Agents write/read from standardized file locations
3. **Separation of Concerns**: Translation logic in agents/skills, math computations in Python
4. **Sequential Workflow**: Each step completes before the next begins
5. **Clear Handoffs**: Output of one agent is input to the next

---

## How It Works

### Step-by-Step Process

1. **User Input**: Provide an English sentence (may contain spelling errors)
   - Example: "The quik brown fox jumps ovr the lazi dog"

2. **Main Orchestrator**:
   - Saves the original sentence to `tmp/original_sentence.txt`
   - Invokes the ENâ†’FR translator agent

3. **Translation Chain**:
   - **Translator 1** (`.claude/agents/translators/translator-1-en-fr.md`): Reads English, translates to French, saves to `tmp/first_hop_translation.md`
   - **Translator 2** (`.claude/agents/translators/translator-2-fr-it.md`): Reads French file, translates to Italian, saves to `tmp/second_hop_translation.md`
   - **Translator 3** (`.claude/agents/translators/translator-3-it-en.md`): Reads Italian file, translates back to English, saves to `tmp/third_hop_translation.md`

4. **Semantic Analysis**:
   - **Orchestrator** reads both original and final translation files
   - Calls `python calculate_distance.py "original" "final"`
   - Python computes embeddings (text â†’ 384-dim vectors)
   - Python calculates cosine distance between vectors
   - Orchestrator reports the semantic drift

5. **Result**: User sees a distance value (0 = identical, 2 = opposite meaning)

### Why This Architecture?

- **Modularity**: Each agent has a single responsibility
- **Scalability**: Easy to add more translation hops or change languages
- **Transparency**: File-based communication makes debugging easy
- **Reusability**: Agents and skills can be reused in other projects

---

## Installation

### Prerequisites

- Python 3.8 or higher
- Claude Code CLI (for user input experiments)

### Step 1: Install Python Dependencies

```bash
pip install -r requirements.txt
```

This installs:
- `sentence-transformers` - Semantic embedding models
- `torch` - Deep learning framework (required by sentence-transformers)
- `numpy` - Numerical computations
- `scipy` - Distance calculations
- `matplotlib` - Visualization (for graphs)
- `transformers` - NLP utilities

### Step 2: Verify Installation

Test the embeddings library:
```bash
python -c "from sentence_transformers import SentenceTransformer; print('Embeddings: OK')"
```

On first run, the embedding model (~90MB) will be downloaded automatically.

---

## Experiment Types

This project supports two distinct experiment types: **User Input Experiments** and **Automated Experiments**.

### User Input Experiments

**Purpose**: Interactive testing with custom sentences containing spelling errors

**How it works**:
- User provides a sentence with typos directly to Claude Code
- Multi-agent system processes the sentence through translation chain
- Agents communicate via file-based messaging
- Results are analyzed and reported in real-time

**Best for**:
- Testing specific sentences
- Understanding how particular typos affect translation
- Interactive exploration of semantic drift
- Demonstrating multi-agent coordination

**Example**:
```
User: "Please analyze this sentence: 'The quik brown fox jumps ovr the lazi dog'"
Claude: [Activates multi-agent system, reports semantic distance]
```

**Translation Chain**: English â†’ French â†’ Italian â†’ English

---

### Automated Experiments

**Purpose**: Comprehensive systematic testing with full qualitative and quantitative analysis

**Requirements**:
- **Sentence length:** >15 words each
- **Typo rates:** 20%, 25%, 30%, 35%, 40%, 45%, 50% (7 rates)
- **Samples:** 3 unique sentences per typo rate = **21 total sentences**

**How it works** (4-Phase Process):

**Phase 1: Sentence Generation (Claude ONLY)**
- Claude creates 21 distinct English sentences covering varied topics
- Each sentence >15 words with rich semantic content
- Claude manually introduces typos at specified rates
- NO Python involvement in this phase

**Phase 2: Translation Processing (Claude Agents)**
- Each sentence runs through 3-hop translation chain
- All 21 sentences processed (63 translation operations total)
- Intermediate translations documented
- Qualitative observations noted (semantic drift, meaning preservation)

**Phase 3: Qualitative Report (Claude ONLY)**
- Comprehensive markdown report with ALL 21 sentences
- Structured table: original, corrupted, translations, observations
- Typo-level analysis and stability metrics
- Conceptual graph description (expected patterns)
- Insights and conclusions

**Phase 4: Quantitative Analysis (Python ONLY)**
- Calculate 21 embedding distances
- Generate matplotlib graph
- Append numerical data to existing report

**Best for**:
- Scientific analysis of typo rate vs semantic drift
- Multi-agent system demonstration
- Systematic experimental methodology
- Comprehensive statistical reporting

**Example**:
```
User: "Run the batch experiment"
Claude: [Executes 21 translation chains (63 total operations), produces analysis report]
```

**Translation Chain**: English â†’ French â†’ Italian â†’ English

**Output Files**:
- `results/quantitative_analysis.md` - Statistical analysis with all 21 sentences
- `results/semantic_drift_analysis.png` - Visualization with 4 subplots (mean distances, individual points, histogram, box plots)
- All generated by Python scripts after Claude completes translations

---

## Usage

### Method 1: User Input Experiments (Interactive)

**Using Claude Code CLI:**

```
Please run the translation drift experiment with this sentence:
"The quik brown fox jumps ovr the lazi dog"
```

Claude will automatically:
1. Activate the main orchestrator
2. Run the translation chain through multiple agents
3. Compute semantic distance
4. Report results

**Example sentences to try**:
- `"The quik brown fox jumps ovr the lazi dog"` (25% typos)
- `"Th qk brwn fx jmps vr th lz dg"` (50% typos)
- `"Hello wrld, hw ar yu tday?"` (Different sentence structure)

### Method 2: Automated Experiments (Claude-Orchestrated Batch)

**Run the complete batch experiment:**
```
User: "Run the batch experiment"
```
or
```
User: "Run automated experiment with multiple typo rates"
```

This will:
- Test typo rates from 20% to 50% (7 rates: 20%, 25%, 30%, 35%, 40%, 45%, 50%)
- Generate 3 sentences per typo rate (21 total sentences)
- Execute 63 translation operations (21 sentences Ã— 3 hops each)
- Calculate comprehensive statistics (average, min, max, std dev per rate)
- Generate visualization and detailed markdown report
- All orchestration handled by Claude agents, analysis by Python

**Customizing the automated experiment:**
To modify the experiment parameters, edit the batch_experiment_orchestrator agent file:
```
- Typo rates: Change from 25%-50% to your desired range
- Iterations: Modify number of sentences per rate
- Base sentence: Use different test sentences
- Translation languages: Modify the language chain
```

### Method 3: Direct Testing (Component Level)

Test individual components through Claude skills:

```
# Test typo injection skill
User: "Use the typo injector skill to add 25% typos to 'Hello world'"

# Test translation agents individually
User: "Translate 'Hello world' from English to French using the ENâ†’FR translator"

# Test embedding analysis
User: "Calculate semantic distance between 'Hello world' and 'Bonjour le monde'"
```

**Note**: All component testing is done through Claude's skill system rather than direct Python calls.

---

## Project Structure

```
.
â”œâ”€â”€ README.md                                     # This file
â”œâ”€â”€ USAGE.md                                      # Quick start guide
â”œâ”€â”€ requirements.txt                              # Python dependencies
â”œâ”€â”€ CHANGELOG.md                                  # Version history
â”œâ”€â”€ SELF_ASSESSMENT.md                            # Project self-assessment
â”œâ”€â”€ OPEN_SOURCE_CONTRIBUTION.md                   # Open source contributions
â”‚
â”œâ”€â”€ .claude/                                      # Multi-agent system
â”‚   â”œâ”€â”€ main.md                                   # Main orchestrator
â”‚   â”œâ”€â”€ settings.local.json                       # Local settings
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                                   # All agent definitions organized by type
â”‚   â”‚   â”œâ”€â”€ translators/                          # Translation agents
â”‚   â”‚   â”‚   â”œâ”€â”€ translator-1-en-fr.md             # English â†’ French
â”‚   â”‚   â”‚   â”œâ”€â”€ translator-2-fr-it.md             # French â†’ Italian
â”‚   â”‚   â”‚   â””â”€â”€ translator-3-it-en.md             # Italian â†’ English
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ orchestrators/                        # Orchestration agents
â”‚   â”‚   â”‚   â”œâ”€â”€ translation-experiment-orchestrator.md # Main experiment controller
â”‚   â”‚   â”‚   â”œâ”€â”€ batch-experiment-orchestrator.md       # Batch experiment runner
â”‚   â”‚   â”‚   â””â”€â”€ embedding-analyzer.md                  # Semantic distance analyzer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ code-reviewer/                        # Code quality review agent
â”‚   â”‚   â”‚   â””â”€â”€ code-reviewer.md                  # Expert code reviewer
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ qa-expert/                            # Quality assurance agent
â”‚   â”‚       â””â”€â”€ qa-expert.md                      # QA testing expert
â”‚   â”‚
â”‚   â”œâ”€â”€ commands/                                 # Command definitions
â”‚   â”‚   â””â”€â”€ run-translation-experiment.md         # Experiment execution command
â”‚   â”‚
â”‚   â””â”€â”€ skills/                                   # Reusable skills (only .md files)
â”‚       â”œâ”€â”€ translate/
â”‚       â”‚   â””â”€â”€ SKILL.md                          # Translation skill (native Claude)
â”‚       â”œâ”€â”€ typo-injector/
â”‚       â”‚   â””â”€â”€ SKILL.md                          # Typo injection (word-based)
â”‚       â”œâ”€â”€ embeddings/
â”‚       â”‚   â””â”€â”€ SKILL.md                          # Embedding computation
â”‚       â””â”€â”€ chart-generator/
â”‚           â””â”€â”€ SKILL.md                          # Chart generation
â”‚
â”œâ”€â”€ scripts/                                      # Python analysis scripts
â”‚   â”œâ”€â”€ calculate_distance.py                     # Single sentence distance (CLI)
â”‚   â””â”€â”€ batch_calculate_distances.py              # Batch distance calculation + visualization
â”‚
â”œâ”€â”€ tmp/                                          # Agent communication files (gitignored)
â”‚   â”œâ”€â”€ original_sentence.txt                     # Original user input
â”‚   â”œâ”€â”€ first_hop_translation.md                  # English â†’ French
â”‚   â”œâ”€â”€ second_hop_translation.md                 # French â†’ Italian
â”‚   â””â”€â”€ third_hop_translation.md                  # Italian â†’ English
â”‚
â”œâ”€â”€ results/                                      # Experiment results
â”‚   â”œâ”€â”€ semantic_drift_analysis.png               # Matplotlib graph (auto-generated)
â”‚   â””â”€â”€ quantitative_analysis.md                  # Statistics table (auto-generated)
â”‚
â”œâ”€â”€ data/                                         # Experiment data
â”‚   â””â”€â”€ experiment_raw_data/                      # Raw data from latest experiment
â”‚       â”œâ”€â”€ sentence_XX_original.txt              # Original sentences (21 files)
â”‚       â”œâ”€â”€ sentence_XX_corrupted.txt             # Corrupted sentences (21 files)
â”‚       â”œâ”€â”€ all_translations_complete.txt         # All translation chains
â”‚       â”œâ”€â”€ distance_results.txt                  # Semantic distances
â”‚       â””â”€â”€ verification_summary.txt              # Typo verification data
â”‚
â””â”€â”€ docs/                                         # Documentation
    â”œâ”€â”€ ARCHITECTURE.md                           # System architecture
    â”œâ”€â”€ MATHEMATICAL_FOUNDATIONS.md               # Mathematical basis
    â”œâ”€â”€ RESEARCH_METHODOLOGY.md                   # Research approach
    â”œâ”€â”€ TESTING.md                                # Test documentation
    â”œâ”€â”€ PROMPT_BOOK.md                            # Prompt engineering guide
    â”œâ”€â”€ PRD.md                                    # Product requirements
    â”œâ”€â”€ SECURITY.md                               # Security considerations
    â”œâ”€â”€ COST_ANALYSIS.md                          # Cost analysis
    â”œâ”€â”€ EDGE_CASES.md                             # Edge case handling
    â”œâ”€â”€ ISO_IEC_25010_COMPLIANCE.md               # Quality compliance
    â””â”€â”€ ADRs/                                     # Architecture Decision Records
        â”œâ”€â”€ ADR-001-multi-agent-design.md
        â”œâ”€â”€ ADR-002-embedding-model-selection.md
        â””â”€â”€ ADR-003-translation-chain-design.md
```

---

## Agent and Skill Descriptions

### Primary Agents (For Translation Experiments)

#### 1. Main Orchestrator (`main.md`)
**Purpose**: Coordinates the entire workflow

**Responsibilities**:
- Receives user input (English sentence with possible typos)
- Saves original sentence to file
- Invokes translator agents in sequence
- Calls embedding analyzer
- Reports final results

**Tools**: Task (to launch sub-agents), Write (to save files), Read

---

#### 2. Translation Chain Agents

**Translator 1** (`.claude/agents/translators/translator-1-en-fr.md`)
- **Purpose**: First hop in translation chain
- **Responsibilities**: Translates English â†’ French, saves to `tmp/first_hop_translation.md`
- **Tools**: Skill (translate), Write

**Translator 2** (`.claude/agents/translators/translator-2-fr-it.md`)
- **Purpose**: Second hop in translation chain
- **Responsibilities**: Reads French, translates to Italian, saves to `tmp/second_hop_translation.md`
- **Tools**: Read, Skill (translate), Write

**Translator 3** (`.claude/agents/translators/translator-3-it-en.md`)
- **Purpose**: Third and final hop - back to English
- **Responsibilities**: Reads Italian, translates to English, saves to `tmp/third_hop_translation.md`
- **Tools**: Read, Skill (translate), Write

---

#### 3. Orchestrator Agents

**Embedding Analyzer** (`.claude/agents/orchestrators/embedding-analyzer.md`)
- **Purpose**: Compute semantic distance between sentences
- **Responsibilities**: Reads original and final sentences, computes embeddings, calculates cosine distance
- **Tools**: Read, Bash (Python scripts), Write
- **Note**: Only agent that uses Python for embeddings/distance

**Translation Experiment Orchestrator** (`.claude/agents/orchestrators/translation-experiment-orchestrator.md`)
- **Purpose**: Main experiment controller
- **Responsibilities**: Manages manual and automated experiment modes, coordinates all agents
- **Tools**: Task, Write, Read, Bash

**Batch Experiment Orchestrator** (`.claude/agents/orchestrators/batch-experiment-orchestrator.md`)
- **Purpose**: Systematic batch testing across multiple typo rates
- **Responsibilities**: Generates corrupted sentences, runs chains, collects statistics
- **Tools**: Task, Write, Read, Bash

---

### Quality Assurance Agents

#### 4. Code Reviewer (`agents/code-reviewer/code-reviewer.md`)
**Purpose**: Expert code review specializing in quality, security, and best practices

**Responsibilities**:
- Review code quality and correctness
- Identify security vulnerabilities
- Assess performance and maintainability
- Provide constructive feedback

**Tools**: Read, Write, Edit, Bash, Glob, Grep
**Focus Areas**: Security, correctness, performance, maintainability, testing, documentation

---

#### 5. QA Expert (`agents/qa-expert/qa-expert.md`)
**Purpose**: Comprehensive quality assurance and testing

**Responsibilities**:
- Design test strategies
- Execute test plans
- Automate testing
- Track quality metrics

**Tools**: Read, Grep, Glob, Bash
**Focus Areas**: Test coverage, defect management, automation, quality metrics

---

### Skills & Utilities

#### 1. Translation (`skills/translate/SKILL.md`)
**Purpose**: Translate text between languages

**Technology**: Uses Claude's native multilingual capabilities

**Capabilities**:
- Supports multiple languages
- Handles text with spelling errors gracefully
- Works with UTF-8 encoding (Hebrew, Arabic, Chinese, etc.)
- No external API calls required

**Usage**: Invoked by translator agents

---

#### 2. Typo Injection (`skills/typo-injector/SKILL.md`)
**Purpose**: Introduce spelling errors at specified rates

**Technology**: Uses Claude's native logic (word-based typo generation)

**Methodology**:
- Word-based approach: 20% = 20% of words have typos
- Four error types: substitution, deletion, duplication, swap
- Mandatory verification step ensures accuracy

**Used by**: Automated experiments and manual typo injection

---

#### 3. Embedding Computation
**Purpose**: Convert text to semantic vector representation

**Technology**: Uses `sentence-transformers` library with `all-MiniLM-L6-v2` model

**Python Script**: `scripts/calculate_distance.py`
- Input: Two sentences as command-line arguments
- Output: Float distance value to stdout
- Called by: `embedding-analyzer` agent

**What it does**:
- Converts text into 384-dimensional vectors
- Captures semantic meaning (not just words)
- Computes cosine distance between vectors

---

## Python Scripts (`/scripts/` folder)

### 1. calculate_distance.py
**Purpose**: Calculate semantic distance between two sentences

**Usage**:
```bash
python scripts/calculate_distance.py "sentence1" "sentence2"
# Output: 0.234567
```

**When Called**:
- By `embedding-analyzer.md` agent for single sentence analysis
- For each sentence pair in experiments

**Output**: Float distance value (0-2 range, printed to stdout)

**Key Features**:
- Handles embeddings computation
- Computes cosine distance
- UTF-8 encoding support

---

### 2. batch_calculate_distances.py
**Purpose**: Batch semantic distance calculation with visualization

**Usage**:
```bash
python scripts/batch_calculate_distances.py
```

**When Called**:
- By `batch-experiment-orchestrator.md` agent
- For comprehensive batch experiment analysis

**Outputs**:
- `results/semantic_drift_analysis.png` - Matplotlib graph with 4 subplots
- `results/quantitative_analysis.md` - Statistics table in markdown

**Generates**:
1. Mean distance with error bars
2. Individual sentence data points
3. Distribution histogram
4. Box plot by typo rate

---

### 3. generate_visualization.py & Others
**Purpose**: Additional analysis utilities

**When Used**: For custom analysis and exploration

---

#### 4. Visualization (via Python scripts)
**Purpose**: Generate charts and save experimental results

**Technology**: Uses `matplotlib` for plotting

**Output**: PNG charts embedded in markdown reports

**Used by**: Automated experiments for result visualization

---

## Experiment Configuration

### User Input Experiments Configuration

- **Original Language**: English
- **Translation Chain**: English â†’ French â†’ Italian â†’ English
- **Input Method**: Direct user input to Claude Code
- **Typo Handling**: User provides pre-existing typos
- **Communication**: File-based agent messaging

### Automated Experiments Configuration

- **Original Language**: English
- **Translation Chain**: English â†’ French â†’ Italian â†’ English
- **Typo Rates Tested**: 20%, 25%, 30%, 35%, 40%, 45%, 50% (7 rates)
- **Sentences per Rate**: 3 unique sentences (21 total sentences)
- **Translation Operations**: 63 total (21 sentences Ã— 3 hops each)
- **Typo Generation**: Claude's typo-injector skill (word-based methodology)
- **Orchestration**: Claude batch_experiment_orchestrator agent
- **Embedding Model**: all-MiniLM-L6-v2 (384 dimensions)
- **Distance Metric**: Cosine distance
- **Verification**: Mandatory 3% tolerance check for typo rate accuracy

### Customization Options

#### Change Translation Languages

**For User Input Experiments**: Edit the agent files to use different language codes

**For Automated Experiments**: Edit the batch_experiment_orchestrator agent configuration:
```
# Modify the agent file to change:
- Translation chain languages
- Typo rates tested
- Number of iterations per rate
- Base sentence used for testing
```

#### Language Codes
- `en` = English, `fr` = French, `es` = Spanish, `he` = Hebrew
- `de` = German, `ja` = Japanese, `zh` = Chinese, `ar` = Arabic
- `ru` = Russian, `it` = Italian, `pt` = Portuguese

#### Change Number of Translation Hops

**For User Input**: Create additional translator agents
**For Automated**: Extend the `translation_chain` list

#### Modify Typo Rates (Automated Only)

Edit the batch_experiment_orchestrator agent:
```
Change: "Typo rates": 25%, 30%, 35%, 40%, 45%, 50%
To: "Typo rates": [your desired percentages]
```

---

## Understanding Results

### What is Semantic Distance?

Semantic distance measures how different two pieces of text are in meaning, not in words.

**Example**:
- "The cat sat on the mat" vs "A feline rested on the rug" = **Low distance** (similar meaning)
- "The cat sat on the mat" vs "The dog ran in the park" = **High distance** (different meaning)

### How Cosine Distance Works

1. **Text â†’ Vector**: Each text is converted to a 384-dimensional vector
2. **Angle Measurement**: Cosine distance measures the angle between vectors
3. **Range**:
   - 0 = vectors point in same direction (identical meaning)
   - 1 = vectors are perpendicular (unrelated)
   - 2 = vectors point in opposite directions (opposite meaning)

### Interpreting Your Results

**Low Distance (< 0.3)**:
- Translation preserved meaning well
- Spelling errors had minimal impact
- The final text conveys the original intent

**Medium Distance (0.3 - 0.6)**:
- Some semantic drift occurred
- Spelling errors introduced ambiguity
- Core meaning partially preserved

**High Distance (> 0.6)**:
- Significant semantic drift
- Spelling errors severely impacted translation
- Final meaning diverged substantially

### Expected Patterns

Generally, you should observe:
1. **Positive correlation**: More typos â†’ higher distance
2. **Non-linear growth**: Distance may increase faster at higher typo rates
3. **Language effects**: Some language pairs preserve meaning better than others

---

## Example Runs

### Example 1: User Input Experiment

**Input**:
```
User: "Please analyze this sentence with typos: 'The quik brown fox jumps ovr the lazi dog'"
```

**Execution Flow**:
```
Main Orchestrator:
  âœ“ Saved original sentence to tmp/original_sentence.txt
  âœ“ Launching ENâ†’FR translator...

Translator 1 (English â†’ French):
  âœ“ Received: "The quik brown fox jumps ovr the lazi dog"
  âœ“ Translated: "Le renard brun rapide saute par-dessus le chien paresseux"
  âœ“ Written to tmp/first_hop_translation.md

Translator 2 (French â†’ Italian):
  âœ“ Read from tmp/first_hop_translation.md
  âœ“ Translated: "La volpe marrone veloce salta sopra il cane pigro"
  âœ“ Written to tmp/second_hop_translation.md

Translator 3 (Italian â†’ English):
  âœ“ Read from tmp/second_hop_translation.md
  âœ“ Translated: "The fast brown fox jumps over the lazy dog"
  âœ“ Written to tmp/third_hop_translation.md

Embedding Analyzer:
  âœ“ Computing embeddings...
  âœ“ Original: [384-dim vector]
  âœ“ Final: [384-dim vector]
  âœ“ Distance: 0.7996

========================================
SEMANTIC DRIFT ANALYSIS
========================================

Original Sentence (English):
"The quik brown fox jumps ovr the lazi dog"

Final Translation (English):
"The fast brown fox jumps over the lazy dog"

Semantic Distance: 0.7996

Interpretation:
Result: High drift (significant semantic change)

The translation chain shows substantial semantic drift.
This reflects cross-lingual embedding differences and
the compound effect of multiple translation hops.
========================================
```

### Example 2: Automated Batch Experiment (November 16, 2025)

**Command** (via Claude Code):
```
User: "Run automated experiment"
```

**Actual Results from Latest Experiment**:
```
================================================================================
AUTOMATED MULTI-HOP TRANSLATION SEMANTIC DRIFT EXPERIMENT
================================================================================

Experiment Date: November 16, 2025
Total Sentences: 21
Typo Rate Range: 20% - 50% (7 levels, 3 sentences each)
Translation Chain: English â†’ French â†’ Italian â†’ English (3 hops)
Verification: 100% pass rate (all 21 sentences verified)

================================================================================
VERIFICATION SUMMARY
================================================================================

âœ“ All 21 sentences passed typo injection verification
âœ“ Average deviation: 1.5% (within 3% threshold)
âœ“ Word-based typo methodology enforced

================================================================================
KEY FINDINGS - SURPRISING NON-LINEAR PATTERN
================================================================================

Typo Rate  â”‚  Mean Distance  â”‚  Interpretation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   20%     â”‚     0.419       â”‚  Moderate drift
   25%     â”‚     0.472       â”‚  Increasing drift
   30%     â”‚     0.633       â”‚  PEAK DRIFT (highest!)
   35%     â”‚     0.439       â”‚  Recovery begins
   40%     â”‚     0.425       â”‚  Surprisingly low drift
   45%     â”‚     0.481       â”‚  Slight increase
   50%     â”‚     0.451       â”‚  Still moderate

UNEXPECTED FINDING: Semantic drift does NOT increase linearly!
- Peak drift at 30% (0.633), not 50% as expected
- Surprising recovery at 40% (0.425)
- Topic/domain matters MORE than typo rate

================================================================================
SAMPLE TRANSLATION CHAINS
================================================================================

[Example: Sentence 1 - 20% Typo Rate]
Original:
  "The ancient library contained thousands of manuscripts documenting
   the scientific discoveries made by scholars throughout medieval
   European history."

Corrupted (4/18 words = 22.2%):
  "The ancent library contained thousands of manuscripst documenting
   the scientfic discoveries made by scholars througout medieval
   European history."

Translation Chain:
  English â†’ French:
    "La bibliothÃ¨que ancienne contenait des milliers de manuscrits..."

  French â†’ Italian:
    "L'antica biblioteca conteneva migliaia di manoscritti..."

  Italian â†’ English:
    "The ancient library contained thousands of manuscripts documenting
     the scientific discoveries..."

Semantic Distance: 0.387 (moderate drift despite typos)

[Example: Sentence 19 - 50% Typo Rate]
Original:
  "Urban planners design sustainable transportation networks that
   reduce traffic congestion minimize environmental impact and
   improve accessibility for residents."

Corrupted (9/18 words = 50.0%):
  "Urban planors design sustainble transportaton networs that reduce
   trafic congestoin minimize enviromental impact and improve
   accesibility for resients."

Translation Chain â†’ English:
  "The urban planners design sustainable transportation networks that reduce
   traffic congestion, minimize environmental impact and improve
   accessibility for residents."

Semantic Distance: 0.436 (LOWER than 30% rate!)

================================================================================
STATISTICAL SUMMARY
================================================================================

Overall Mean Distance: 0.467
Standard Deviation: 0.128
Range: 0.295 - 0.824
Pearson Correlation (typo rate vs distance): -0.046 (essentially zero!)

CONCLUSION: LLM translators act as implicit error correctors, recovering
semantic meaning even at high corruption rates through context inference.

================================================================================

Complete Results Available:
  Main Report: results/quantitative_analysis.md
  Visualization: results/semantic_drift_analysis.png
  Raw Data: data/experiment_raw_data/
```

---

## Troubleshooting

### Common Issues

**1. ModuleNotFoundError: No module named 'sentence_transformers'**
```bash
pip install -r requirements.txt
```

**2. Translation Issues**
- Claude handles translation natively
- No external API or internet required for translation
- Only embeddings require model download (first run only)

**3. Model Download Delays**
- First run downloads the embedding model (~90MB)
- This happens once; subsequent runs are fast
- Ensure stable internet connection

**4. File Not Found: /tmp/...**
- Ensure agents ran in sequence
- Check that each agent completed successfully
- Verify tmp/ directory exists in project root

**5. Experiment Fails**
- Check Python path and dependencies
- Ensure `results/` directory is writable
- Verify all agents completed their tasks

---

## Academic Context

### Learning Objectives

This project demonstrates:
1. **Multi-agent orchestration**: Coordinating autonomous agents
2. **Inter-agent communication**: File-based message passing
3. **Separation of concerns**: Agents vs skills vs Python scripts
4. **NLP pipeline design**: Translation â†’ embedding â†’ analysis
5. **Semantic evaluation**: Using embeddings to measure quality
6. **Error propagation**: How noise compounds through transformations
7. **Experimental design**: User input vs automated batch testing

### Research Questions

- How do spelling errors affect semantic drift?
- Is the relationship linear or non-linear?
- Do different language chains show different patterns?
- At what typo rate does meaning break down completely?
- How do multi-agent systems compare to monolithic approaches?

### Extensions

Possible project extensions:
- Test different language chains (e.g., English â†’ Chinese â†’ Arabic â†’ Russian)
- Compare different embedding models (e.g., multilingual-BERT)
- Add more translation hops (4, 5, 6 hops)
- Inject different types of errors (grammar, punctuation, word order)
- Create real-time visualization dashboards
- Implement error recovery mechanisms
- Add confidence scoring for translations

---

## Quick Start Commands

```bash
# Install dependencies
pip install -r requirements.txt

# Test embeddings
python -c "from sentence_transformers import SentenceTransformer; model = SentenceTransformer('all-MiniLM-L6-v2'); print('Embeddings: OK')"

# Test distance calculator
python calculate_distance.py "Hello world" "Bonjour monde"

# Run manual mode experiment (within Claude Code)
# Ask Claude: "Analyze this sentence: [your sentence with typos]"

# Run automated experiment (within Claude Code)
# Ask Claude: "Run automated experiment"
```

---

## License

This is an academic assignment project for "LLMs and Multi-Agent Orchestration" course.
Feel free to use and modify for educational purposes.

---

## Author

Created as part of the MLDS program assignment on multi-agent systems.

**Key Takeaway**: This project shows how multi-agent systems can handle complex, multi-step workflows with both interactive user input and automated batch processing. The separation between coordination (agents), translation (skills), computation (Python), and experimentation (automated scripts) creates a modular, maintainable system that supports both research and interactive exploration.

---

**Happy experimenting! ðŸš€**
